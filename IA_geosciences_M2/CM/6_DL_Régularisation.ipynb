{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XleADhB8JZ7"
      },
      "source": [
        "# **Régularisation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwS1PxbbECAA"
      },
      "source": [
        "### Import des librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhNCGz8yET3a"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGaxsPmk4SZR"
      },
      "source": [
        "## Télécharger un modèle pré entrainé comme InceptionV3 (exemple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBK57CxtqPLV"
      },
      "source": [
        "###  En utilisant [ce lien](https://keras.io/applications)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ACtrdl0be9L"
      },
      "source": [
        "Dans cette séance nous n'allons pas utiliser de modèle téléchargé car ils sont généralement assez coûteux à entrainer, mais l'exemple ci-dessous vous montre qu'il est très facile de récupérer un modèle pré-entrainé.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqRNxTBEqLNQ"
      },
      "source": [
        "model = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goEfUnreqYPA"
      },
      "source": [
        "### Afficher les informations de ce modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oA6KVeAqeEV"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZOKRqasEVEW"
      },
      "source": [
        "### Charger les données MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x6sqAo6EW6t"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# réduire la taille du train pour accélérer les experiences\n",
        "nnn=1024\n",
        "x_train = x_train[:nnn]\n",
        "y_train = y_train[:nnn]\n",
        "\n",
        "print(\"x_train\",x_train.shape)\n",
        "print(\"Nombre d'images pour entrainer:\",x_train.shape[0])\n",
        "print(\"Nombre d'images pour tester:\",x_test.shape[0])\n",
        "print(\"La taille d'une image:\",x_train.shape[1:],\"ce qui fait au total:\",\n",
        "      x_train.shape[1]*x_train.shape[2],\"pixels\")\n",
        "print(\"La liste des classes:\",np.unique(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBb0frSvEZLC"
      },
      "source": [
        "### Définition d'une fonction qui transforme en représentation binaire pour plusieurs classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcP1svsvEfTk"
      },
      "source": [
        "def transform_labels(y_train,y_test):\n",
        "  \"\"\"\n",
        "  Cette fonction transform les classes non-binaire à une représentation binaire\n",
        "  Par exemple si on a une liste de 6 fleures chacune peut avoir une des 3 classes\n",
        "  Entrée: [1,3,3,2,1,2]\n",
        "  Sortie: [\n",
        "           [1,0,0], # class 1\n",
        "           [0,0,1], # class 3\n",
        "           [0,0,1], # class 3\n",
        "           [0,1,0], # class 2\n",
        "           [1,0,0], # class 1\n",
        "           [0,1,0]  # class 2\n",
        "          ]\n",
        "  \"\"\"\n",
        "\n",
        "  # concatener train et test\n",
        "  y_train_test = np.concatenate((y_train,y_test),axis =0)\n",
        "\n",
        "  # init un encoder Label\n",
        "  encoder = LabelEncoder()\n",
        "  # transformer de [1,3,3,2,1,2] à [0,2,2,1,0,1]\n",
        "  new_y_train_test = encoder.fit_transform(y_train_test)\n",
        "\n",
        "  # init un encoder one-hot\n",
        "  encoder = OneHotEncoder()\n",
        "  # préparer la transformation de [0,2,2,1,0,1] à la représentation binaire\n",
        "  encoder.fit(new_y_train_test.reshape(-1,1))\n",
        "\n",
        "  # resplit the train and test\n",
        "  new_y_train = new_y_train_test[0:len(y_train)]\n",
        "  new_y_test = new_y_train_test[len(y_train):]\n",
        "\n",
        "  return new_y_train, new_y_test, encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A3HGJorEh9t"
      },
      "source": [
        "### Visualiser quelques images en spécifiant que c'est du noir et blanc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBker-GsEjy4"
      },
      "source": [
        "plt.subplot(221)\n",
        "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(x_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DEpBeqkElDU"
      },
      "source": [
        "### Normaliser les données pour que chaque pixel soit entre 0 et 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmmBh6rpEm5k"
      },
      "source": [
        "# diviser par 255 pour que tout soit entre 0 et 1\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-JNJH-PE3Uz"
      },
      "source": [
        "## Augmentation de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9_T3xfvNtss"
      },
      "source": [
        "### Définir un générateur qui prend en entrée un jeu de données et retourne son augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izH-OVdUNePQ"
      },
      "source": [
        "# utiliser un datagen de keras\n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(featurewise_center=True,\n",
        "                                                       featurewise_std_normalization=True,\n",
        "                                                       rotation_range=20, # angle de rotation aléatoire\n",
        "                                                       width_shift_range=0.1, #  décalage horizontale\n",
        "                                                       height_shift_range = 0.1, # décalage vertical\n",
        "                                                       brightness_range = (0.0,1.0) # changement de l'eclairage\n",
        "                                                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5evB40kpZU16"
      },
      "source": [
        "### Ajouter une dimension vide pour remplacer le RGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1i467kyZXIw"
      },
      "source": [
        "x_train = x_train[..., np.newaxis]\n",
        "x_test = x_test[..., np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW53UJ7vQaXG"
      },
      "source": [
        "### Tester l'augmentation sur 9 images pour voir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R51vB50wQfKA"
      },
      "source": [
        "for i in range(0, 9):\n",
        "\tplt.subplot(330 + 1 + i)\n",
        "\tplt.imshow(x_train[i,:,:,0], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n",
        "# donner les données à augmenter\n",
        "datagen.fit(x_train,augment=True)\n",
        "\n",
        "# itérer sur une augmentation en ligne\n",
        "for x_batch, y_batch in datagen.flow(x_train,y_train,batch_size = 9,shuffle=False):\n",
        "  # tracer celle qui a subi une modification aléatorie\n",
        "  for i in range(9):\n",
        "    plt.subplot(330+1+i)\n",
        "    plt.imshow(x_batch[i,:,:,0], cmap=plt.get_cmap('gray'))\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3rncv0tEogL"
      },
      "source": [
        "### Transformer les classes en représentation binaire (one-hot encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rYidexdE1yZ"
      },
      "source": [
        "y_train_binaire,y_test_binaire,encoder = transform_labels(y_train,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7G4LOxTfiEY"
      },
      "source": [
        "### Créer un modèle convolutif à deux couches avec la sortie softmax classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEAQE0jBgCL8"
      },
      "source": [
        "# créer la couche  d'entrée\n",
        "input_shape = x_train.shape[1:]\n",
        "input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "# créer la couche convolutive\n",
        "hidden_conv_layer_1 = keras.layers.Conv2D(filters=16,\n",
        "                                          kernel_size=(5,5) ,strides=1,\n",
        "                                          padding='valid',activation='relu')(input_layer)\n",
        "# créer la deuxième couche convolutive\n",
        "hidden_conv_layer_2 = keras.layers.Conv2D(filters=8,\n",
        "                                          kernel_size=(5,5) ,strides=1,\n",
        "                                          padding='valid')(hidden_conv_layer_1)\n",
        "\n",
        "# ajouter une couche de batch normalization avant l'activation\n",
        "batch_norm_layer_2 = keras.layers.BatchNormalization(axis=-1)(hidden_conv_layer_2)\n",
        "\n",
        "# ajouter l'activation relu\n",
        "activation_layer_2 = keras.layers.Activation('relu')(batch_norm_layer_2)\n",
        "\n",
        "# aplatir l'image\n",
        "flatenned_layer_2 = keras.layers.Flatten()(activation_layer_2)\n",
        "\n",
        "nb_classes= len(np.unique(y_train))\n",
        "\n",
        "# créer la couche de sortie\n",
        "output_layer = keras.layers.Dense(units=nb_classes,activation='softmax')(flatenned_layer_2)\n",
        "\n",
        "# créer le modèle en liant l'input à l'output\n",
        "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# visualiser le modèle construit\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrpZbGyWhNPn"
      },
      "source": [
        "### Entrainer le modèle avec l'interface de data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyNIf3CLhRnD"
      },
      "source": [
        "# choisir l'algorithme d'optimization\n",
        "optimizer_algo = keras.optimizers.SGD(lr=0.1)\n",
        "\n",
        "# fonction de coût qu'on veut optimiser\n",
        "cost_function = keras.losses.categorical_crossentropy\n",
        "\n",
        "# compiler le modèle\n",
        "model.compile(loss=cost_function,optimizer=optimizer_algo, metrics=['accuracy'])\n",
        "\n",
        "# mini batch size et le nombre d'epoque\n",
        "mini_batch_size = 128\n",
        "nb_epochs = 100\n",
        "\n",
        "# entrainer l'augmenteur d'images\n",
        "datagen.fit(x_train,augment=True)\n",
        "\n",
        "# entrainer en utilisant l'interface d'augmentation de données\n",
        "for epoch in range(nb_epochs):\n",
        "  batches = 0\n",
        "  for x_batch,y_batch in datagen.flow(x_train,y_train,batch_size=mini_batch_size):\n",
        "    y_batch_binaire = encoder.transform(y_batch[:,np.newaxis])\n",
        "    y_batch_binaire = y_batch_binaire.toarray()\n",
        "    model.fit(x_batch,y_batch_binaire,verbose=True)\n",
        "    batches += 1\n",
        "    if batches > len(x_train) / mini_batch_size:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYsAqZIi6nYQ"
      },
      "source": [
        "### Evaluer sur le test de MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFUXWqRY6qLn"
      },
      "source": [
        "y_test_binaire_now = encoder.transform(y_test_binaire[...,np.newaxis])\n",
        "\n",
        "y_test_binaire_now = y_test_binaire_now.toarray()\n",
        "\n",
        "loss,acc = model.evaluate(x_test,y_test_binaire_now,verbose=False)\n",
        "\n",
        "print(\"L'accuracy sur l'ensemble de test est :\",acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6vemrOp4HU8"
      },
      "source": [
        "## Transfer learning entre le dataset Fashion_MNIST et MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYr5-md24NOR"
      },
      "source": [
        "### Télécharger Fashion_MNIST  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kphG8Uv64MeG"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train[:1000]\n",
        "y_train = y_train[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCr6Qj-w49VA"
      },
      "source": [
        "### Afficher des exemples du nouveau jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx_tfAGD5FGP"
      },
      "source": [
        "plt.subplot(221)\n",
        "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(x_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4XJ2P4f5W-V"
      },
      "source": [
        "### Normaliser les données pour que chaque pixel soit entre 0 et 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl2igqHe5Yop"
      },
      "source": [
        "# diviser par 255 pour que tout soit entre 0 et 1\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QA0mLb65Lrv"
      },
      "source": [
        "## Transformer en classes one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2iAEZoX5Sa9"
      },
      "source": [
        "y_train_binaire,y_test_binaire,encoder = transform_labels(y_train,y_test)\n",
        "\n",
        "y_train_binaire = encoder.transform(y_train_binaire[...,np.newaxis])\n",
        "y_test_binaire = encoder.transform(y_test_binaire[...,np.newaxis])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbJpSKEG5ich"
      },
      "source": [
        "### Ajouter une dimension vide pour remplacer le RGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLW1xdif5whO"
      },
      "source": [
        "x_train = x_train[..., np.newaxis]\n",
        "x_test = x_test[..., np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW9N3hQY50xB"
      },
      "source": [
        "### Évaluer sur Fashion_MNIST la performance du modèle déjà entrainé sur MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7NiRDPn58CH"
      },
      "source": [
        "if type(y_test_binaire) != np.ndarray:\n",
        "  y_test_binaire = y_test_binaire.toarray()\n",
        "\n",
        "loss,acc = model.evaluate(x_test,y_test_binaire,verbose=False)\n",
        "\n",
        "print(\"L'accuracy sur l'ensemble du test est :\",acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECiQATf56hHc"
      },
      "source": [
        "### Re-entrainer le modèle sur l'ensemble du train de Fashion_MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm-7zhcB_bAI"
      },
      "source": [
        "y_train_binaire = y_train_binaire.toarray()\n",
        "\n",
        "history = model.fit(x_train,y_train_binaire,batch_size = 256, epochs=100, validation_split = 0.3, verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b701KMzALog"
      },
      "source": [
        "### Tracer la variation de l'accuracy sur le train et sur le validation set en fonction du nombre d'epoque"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNlnKXBUAQDL"
      },
      "source": [
        "history_dict = history.history\n",
        "loss_train_epochs = history_dict['accuracy']\n",
        "loss_val_epochs = history_dict['val_accuracy']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_train_epochs,color='blue',label='train_acc')\n",
        "plt.plot(loss_val_epochs,color='red',label='val_acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.savefig('epoch-loss.pdf')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhIuN1dlAmJ5"
      },
      "source": [
        "## **Exercices**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FqMY1Z7AndP"
      },
      "source": [
        "Entrainer un modèle (avec l'architecture leNet-5) sur 1000 images dans FASHION_MNIST et le re-entrainer sur MNIST (si c'est possible ajouter une couche [Dropout](https://keras.io/layers/core/#dropout) avec un rate de 0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aFKryVxAhom"
      },
      "source": [
        "### Construire un modèle qui marche assez bien sur Fashion_Mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuxUcdDSAu37"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "# télécharger les données fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# réduire la taille du train pour accélérer les experiences\n",
        "nnn=1024\n",
        "x_train = x_train[:nnn]\n",
        "y_train = y_train[:nnn]\n",
        "\n",
        "# diviser par 255 pour que tout soit entre 0 et 1\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "\n",
        "# one-hot encoding\n",
        "y_train,y_test,encoder = transform_labels(y_train,y_test)\n",
        "y_train_binaire = encoder.transform(y_train[...,np.newaxis]).toarray()\n",
        "y_test_binaire = encoder.transform(y_test[...,np.newaxis]).toarray()\n",
        "\n",
        "# ajouter une dimension pour remplacer le RGB\n",
        "x_train = x_train[..., np.newaxis]\n",
        "x_test = x_test[..., np.newaxis]\n",
        "\n",
        "# créer le modèle\n",
        "# créer la couche d'entrainement\n",
        "input_shape = x_train.shape[1:]\n",
        "input_layer = keras.layers.Input(input_shape)\n",
        "# créer la première covolution\n",
        "conv_1 = keras.layers.Conv2D(filters=6,kernel_size=(5,5),padding='same',activation='sigmoid')(input_layer)\n",
        "# créer le subsampling ou bien le pooling\n",
        "pool_1 = keras.layers.MaxPooling2D(pool_size=2)(conv_1)\n",
        "# ajouter un dropout de 0.3\n",
        "drop_1 = keras.layers.Dropout(0.3)(pool_1)\n",
        "\n",
        "# créer la deuxième convolution\n",
        "conv_2 = keras.layers.Conv2D(filters=16,kernel_size=(5,5),padding='valid',activation='sigmoid')(drop_1)\n",
        "# créer le pooling 2\n",
        "pool_2 = keras.layers.MaxPooling2D(pool_size=2)(conv_2)\n",
        "# ajouter un dropout de 0.3\n",
        "drop_2 = keras.layers.Dropout(0.3)(pool_2)\n",
        "\n",
        "# aplatir l'image\n",
        "flattened_layer_2 = keras.layers.Flatten()(drop_2)\n",
        "\n",
        "# un fully connected ou bien un Dense layer\n",
        "layer_3 = keras.layers.Dense(units=120, activation='sigmoid')(flattened_layer_2)\n",
        "# ajouter un dropout de 0.3\n",
        "drop_3 = keras.layers.Dropout(0.3)(layer_3)\n",
        "\n",
        "# un fully connected ou bien un Dense layer\n",
        "layer_4 = keras.layers.Dense(units=84, activation='sigmoid')(drop_3)\n",
        "# ajouter un dropout de 0.3\n",
        "drop_4 = keras.layers.Dropout(0.3)(layer_4)\n",
        "\n",
        "# la dernière couche qui a un nombre de neuroe égale au nombre de classes\n",
        "nb_classes= y_train_binaire.shape[1]\n",
        "output_layer = keras.layers.Dense(units=nb_classes,activation='softmax')(drop_4)\n",
        "\n",
        "# construire le modèle\n",
        "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# afficher les informations\n",
        "model.summary()\n",
        "\n",
        "# entrainer\n",
        "\n",
        "# choisir le taux d'apprentissage pour la descente du gradient\n",
        "optimizer_algo = keras.optimizers.Adam(lr=0.01)\n",
        "\n",
        "# fonction de cout\n",
        "cost_function = keras.losses.categorical_crossentropy\n",
        "\n",
        "# compiler le modèle\n",
        "model.compile(loss=cost_function,optimizer=optimizer_algo, metrics=['accuracy'])\n",
        "\n",
        "# entrainer\n",
        "history = model.fit(x_train,y_train_binaire,batch_size=256,epochs=100,verbose=False,\n",
        "                   validation_split=0.3)\n",
        "\n",
        "# evaluer sur le test\n",
        "loss,acc = model.evaluate(x_test,y_test_binaire,verbose=False)\n",
        "print(\"L'accuracy sur l'ensemble du test est:\",acc)\n",
        "\n",
        "# tracer l'evaluation de l'accuracy\n",
        "history_dict = history.history\n",
        "loss_train_epochs = history_dict['accuracy']\n",
        "loss_val_epochs = history_dict['val_accuracy']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_train_epochs,color='blue',label='train_acc')\n",
        "plt.plot(loss_val_epochs,color='red',label='val_acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.savefig('epoch-loss.pdf')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CRQ9lHBAoNQ"
      },
      "source": [
        "### Télécharger les données MNIST et re-entrainer le modèle pour 100 époques et visualiser l'history (n'oubilier pas le pré-traitement des données)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWlnhpKMBP8a"
      },
      "source": [
        "# télécharger les données mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# réduire la taille du train pour accélérer les experiences\n",
        "nnn=1024\n",
        "x_train = x_train[:nnn]\n",
        "y_train = y_train[:nnn]\n",
        "\n",
        "# diviser par 255 pour que tout soit entre 0 et 1\n",
        "x_train = x_train/255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# one-hot encoding\n",
        "y_train,y_test,encoder = transform_labels(y_train,y_test)\n",
        "y_train_binaire = encoder.transform(y_train[...,np.newaxis]).toarray()\n",
        "y_test_binaire = encoder.transform(y_test[...,np.newaxis]).toarray()\n",
        "\n",
        "# ajouter une dimension pour remplacer le RGB\n",
        "x_train = x_train[..., np.newaxis]\n",
        "x_test = x_test[..., np.newaxis]\n",
        "\n",
        "# entrainer\n",
        "history = model.fit(x_train,y_train_binaire,batch_size=256,epochs=100,verbose=False,\n",
        "                   validation_split=0.3)\n",
        "\n",
        "# evaluer sur le test\n",
        "loss,acc = model.evaluate(x_test,y_test_binaire,verbose=False)\n",
        "print(\"L'accuracy sur l'ensemble du test est:\",acc)\n",
        "\n",
        "# tracer l'evaluation de l'accuracy\n",
        "history_dict = history.history\n",
        "loss_train_epochs = history_dict['accuracy']\n",
        "loss_val_epochs = history_dict['val_accuracy']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_train_epochs,color='blue',label='train_acc')\n",
        "plt.plot(loss_val_epochs,color='red',label='val_acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.savefig('epoch-loss.pdf')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Ove4d6lvIE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}