{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URhdm33F0WEl"
      },
      "source": [
        "# **Convolution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdZxBOywgco8"
      },
      "source": [
        "### Import des librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJN3vLNGf__S"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiot3tcvgfvk"
      },
      "source": [
        "### Charger les données MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7q7MCJegiXk"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# réduire la taille du train pour accélérer les experiences\n",
        "nnn=1000\n",
        "x_train = x_train[:nnn]\n",
        "y_train = y_train[:nnn]\n",
        "\n",
        "print(\"x_train\",x_train.shape)\n",
        "print(\"Nombre d'image pour entrainer:\",x_train.shape[0])\n",
        "print(\"Nombre d'image pour tester:\",x_test.shape[0])\n",
        "print(\"La taille d'une image:\",x_train.shape[1:],\"ce qui fait au total:\",\n",
        "      x_train.shape[1]*x_train.shape[2],\"pixels\")\n",
        "print(\"La liste des classes:\",np.unique(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55Ctl7itgldO"
      },
      "source": [
        "### Définition d'une fonction qui transforme en représentation binaire pour plusieurs classes  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiBACsnUgpL6"
      },
      "source": [
        "def transform_labels(y_train,y_test):\n",
        "  \"\"\"\n",
        "  Cette fonction transform les classes non-binaire à une représentation binaire\n",
        "  Par exemple si on a une liste de 6 fleures chacune peut avoir une des 3 classes\n",
        "  Entrée: [\n",
        "           1,\n",
        "           3,\n",
        "           3,\n",
        "           2,\n",
        "           1,\n",
        "           2\n",
        "          ]\n",
        "\n",
        "  Sortie: [\n",
        "           [1,0,0], # class 1\n",
        "           [0,0,1], # class 3\n",
        "           [0,0,1], # class 3\n",
        "           [0,1,0], # class 2\n",
        "           [1,0,0], # class 1\n",
        "           [0,1,0]  # class 2\n",
        "          ]\n",
        "  \"\"\"\n",
        "\n",
        "  print('y_train',y_train.shape)\n",
        "  print('y_test',y_test.shape)\n",
        "\n",
        "  # concatener train et test\n",
        "  y_train_test = np.concatenate((y_train,y_test),axis =0)\n",
        "\n",
        "  # init un encoder Label\n",
        "  encoder = LabelEncoder()\n",
        "  # transformer de [1,3,3,2,1,2] à [0,2,2,1,0,1]\n",
        "  new_y_train_test = encoder.fit_transform(y_train_test)\n",
        "\n",
        "  # init un encoder one-hot\n",
        "  encoder = OneHotEncoder()\n",
        "  # transformer de [0,2,2,1,0,1] à la représentation binaire\n",
        "  new_y_train_test = encoder.fit_transform(new_y_train_test.reshape(-1,1))\n",
        "\n",
        "  # resplit the train and test\n",
        "  new_y_train = new_y_train_test[0:len(y_train)]\n",
        "  new_y_test = new_y_train_test[len(y_train):]\n",
        "\n",
        "  print('new_y_train',new_y_train.shape)\n",
        "  print('new_y_test',new_y_test.shape)\n",
        "\n",
        "  return new_y_train.toarray(), new_y_test.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeQ3Txangrpy"
      },
      "source": [
        "### Visualiser quelques images en spécifiant que c'est du noir et blanc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sledl0oagw-B"
      },
      "source": [
        "plt.subplot(221)\n",
        "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(x_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVhhK6MenVZY"
      },
      "source": [
        "### Normaliser les données pour que chaque pixel soit entre 0 et 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV5jXDqNnWH0"
      },
      "source": [
        "# diviser par 255 pour que tout soit entre 0 et 1\n",
        "x_train = x_train/255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd0V_QiqgzOv"
      },
      "source": [
        "## Entrainer le réseau de neurones convolutif qui correspond au slide 36"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01eKnWDJncf6"
      },
      "source": [
        "### Transformer les classes en représentation binaire (one-hot encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJTAog_xnI22"
      },
      "source": [
        "y_train_binaire,y_test_binaire = transform_labels(y_train,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR2E7kMjpzfu"
      },
      "source": [
        "### Transformer la forme des images (ajouter une dimension vide pour dire qu'on ait un seul canal - gris au lieu de trois pour RGB comme les images couleurs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udOdWWeTqCba"
      },
      "source": [
        "print(x_train.shape)\n",
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
        "print(x_train.shape)\n",
        "# même chose pour le test set\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_b-I0W5nfTd"
      },
      "source": [
        "### Créer la couche d'entrée qui a la même shape que celle d'une instance dans `x_train`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifl6m0H4ni00"
      },
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "input_layer = keras.layers.Input(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpRr74Diqsn3"
      },
      "source": [
        "### Créer une couche convolutive cachée qui contient 8 filtres avec l'activation `relu`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7wPJzAIrSRv"
      },
      "source": [
        "# padding: 'valid' -> on ne remplis pas l'image en entrée donc la convolution réduit la taille de l'image\n",
        "#          'same'  -> on remplis l'image en entrée pour garder sa taille après la convolution\n",
        "padding = 'same'\n",
        "\n",
        "# spécifier la taille du stride\n",
        "stride = 1\n",
        "\n",
        "# spécifier la taille du filtre (ou kernel): (3,3) signifie 3x3\n",
        "kernel_size = (3,3)\n",
        "\n",
        "# spécifier le nombre de filtres\n",
        "filters = 8\n",
        "\n",
        "# spécifier l'activation ReLU\n",
        "activation = 'relu'\n",
        "\n",
        "# créer la couche convolutive 2D en lui spécifiant les hyper-paramètres et la lier à la couche d'entrée\n",
        "hidden_conv_layer_1 = keras.layers.Conv2D(filters=filters,\n",
        "                                          kernel_size=kernel_size,strides=stride,\n",
        "                                          padding=padding,activation=activation)(input_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_um7YqquLu8"
      },
      "source": [
        "### Lier un max pooling à la couche convolutive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPsQA2CKudzH"
      },
      "source": [
        "# spécifier la taille du pooling: (2,2) signifie 2x2\n",
        "pool_size = (2,2)\n",
        "\n",
        "# spécifier le stride\n",
        "stride = 2\n",
        "\n",
        "# spécifier le padding\n",
        "padding = 'valid'\n",
        "\n",
        "# créer l'opération Max Pooling pour 2D (pour les images c'est souvent 2D)\n",
        "pooling_conv_layer_1 = keras.layers.MaxPooling2D(pool_size = pool_size, strides = stride,\n",
        "                                          padding=padding)(hidden_conv_layer_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jqzy0qSvt7V"
      },
      "source": [
        "### Aplatir la sortie du pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQWjgOZyNng_"
      },
      "source": [
        "# on transforme la sortie du pooling (qui est une image) en un vecteur\n",
        "flattened_layer_1 = keras.layers.Flatten()(pooling_conv_layer_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHQyRDVJN_Bj"
      },
      "source": [
        "### Créer la couche de sortie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eFfTb4rOElJ"
      },
      "source": [
        "# Cette couche correspond à la clasification\n",
        "# donc elle contient C neurones avec C étant le nombre de classes\n",
        "# elle utilise la fonction d'activation softmax\n",
        "# cette couche pren en entrée la couche apaltie (flattened)\n",
        "\n",
        "nb_classes = y_train_binaire.shape[1]\n",
        "\n",
        "output_layer = keras.layers.Dense(units=nb_classes,activation='softmax')(flattened_layer_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxADH5FJOmPI"
      },
      "source": [
        "### Créer maintenant le modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAqtLXrrOuC3"
      },
      "source": [
        "model = keras.models.Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_apEDvZ3OvYk"
      },
      "source": [
        "### Visualiser les informations du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_sHT3l6OxEH"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyp9WOWlOyiB"
      },
      "source": [
        "### Choisir l'algorithme d'optimisation avec un learning rate de 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaMInOnXO1B6"
      },
      "source": [
        "learning_rate = 0.01\n",
        "optimizer_algo = keras.optimizers.SGD(lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPj0KvV8O2g0"
      },
      "source": [
        "### Choisir la fonction de coût qu'on veut optimiser: (Categorical Cross-Entropy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw3XvAJkO4AA"
      },
      "source": [
        "cost_function = keras.losses.categorical_crossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqp6MZh_O5Ys"
      },
      "source": [
        "### Compiler le modèle en lui indiquant qu'on veut mesurer aussi l'accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3lJ5LXbO8LY"
      },
      "source": [
        "model.compile(loss=cost_function,optimizer=optimizer_algo, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1N-syiKO-1F"
      },
      "source": [
        "### Spécifier le fait qu'on veut sauvegarder le meilleur modèle sur le valdiation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE1Gh-3wPAoF"
      },
      "source": [
        "model_checkpoint = keras.callbacks.ModelCheckpoint('best-model.h5', monitor='val_loss', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9tBx7iePCdz"
      },
      "source": [
        "## Entrainement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRpHraKiPGll"
      },
      "source": [
        "### Choisir le batch size et le nombre d'époques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq0fsyNRPKel"
      },
      "source": [
        "mini_batch_size = 256\n",
        "nb_epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv7tMdEMPLu9"
      },
      "source": [
        "### Entrainer en lui spécifiant d'utiliser une partie du train pour la validation des hyper-paramèteres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_wQsjgwPNlu"
      },
      "source": [
        "percentage_of_train_as_validation = 0.3\n",
        "history = model.fit(x_train,y_train_binaire,batch_size=mini_batch_size,\n",
        "                    epochs=nb_epochs,verbose=False,\n",
        "                    validation_split=percentage_of_train_as_validation,\n",
        "                    callbacks=[model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-FfZiUPR3n"
      },
      "source": [
        "### Tracer la variation du taux d'erreur sur le train et sur le validation set en fonction du nombre d'epoques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWoYFF8JPTaR"
      },
      "source": [
        "history_dict = history.history\n",
        "loss_train_epochs = history_dict['loss']\n",
        "loss_val_epochs = history_dict['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_train_epochs,color='blue',label='train_loss')\n",
        "plt.plot(loss_val_epochs,color='red',label='val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.savefig('epoch-loss.pdf')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPi2HitpPZZi"
      },
      "source": [
        "### Choisir le modèle sauveguardé"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBs8HbPcPa-t"
      },
      "source": [
        "model = keras.models.load_model('best-model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUCy1BIvOkTS"
      },
      "source": [
        "## **Exercices**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HER0YlDOlvY"
      },
      "source": [
        "### Evaluer sur le train et sur le test le modèle choisi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJOudU9F26A9"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x5qSTGJ27T9"
      },
      "source": [
        " ### Corrigé :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz6Hzhr3OsoK"
      },
      "source": [
        "loss,acc = model.evaluate(x_train,y_train_binaire,verbose=False)\n",
        "\n",
        "print(\"L'accuracy sur l'ensemble du train est:\",acc)\n",
        "\n",
        "loss,acc = model.evaluate(x_test,y_test_binaire,verbose=False)\n",
        "\n",
        "print(\"L'accuracy sur l'ensemble du test est:\",acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5NbM8q8O9-E"
      },
      "source": [
        "### Construire le modèle du slide 38 en ignorant dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeNStpAw3Q7Q"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pBBfltJ3SLe"
      },
      "source": [
        " ### Corrigé :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm6KnXj1PNDN"
      },
      "source": [
        "# restart keras and tesnorflow session\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# cherche le nombre de classe\n",
        "nb_classes = y_train_binaire.shape[1]\n",
        "\n",
        "# créer la couhce d'entrée qui a la meme shape qu'un image\n",
        "input_shape = x_train.shape[1:]\n",
        "input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "#créer la première couche de convolution et le lier à la couche d'entrée\n",
        "# n'oublier pas de spécifier les hyper-paramètres :\n",
        "# nombre de filtres, padding, la taille du filtre, le stride, l'activation\n",
        "hidden_conv_layer_1 = keras.layers.Conv2D(filters=10, padding='valid',\n",
        "                                          kernel_size=(5,5), strides=1,\n",
        "                                         activation='relu')(input_layer)\n",
        "# créer l'operation max pooling qui prend en entrée la première convolutioom\n",
        "hidden_pooling_layer_1 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=2,\n",
        "                                                  padding='valid')(hidden_conv_layer_1)\n",
        "# créer la deuxième convolution qui prend en entrée le pooling précedent\n",
        "# n'oublier pas de spécifier les hyperparamèteres\n",
        "hidden_conv_layer_2 = keras.layers.Conv2D(filters=20, padding='valid',\n",
        "                                         kernel_size=(5,5),strides=1,\n",
        "                                         activation='relu')(hidden_pooling_layer_1)\n",
        "# créer le max pooling qui est liée à la convolution précédente\n",
        "hidden_pooling_layer_2 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=2,\n",
        "                                            padding='valid')(hidden_conv_layer_2)\n",
        "\n",
        "# ignorer le dropout à cette séance\n",
        "# il faut maintenant aplatir l'image en utilisant le layer Flatten\n",
        "# qui est lié au pooling précédent\n",
        "flatenned_layer_2 = keras.layers.Flatten()(hidden_pooling_layer_2)\n",
        "\n",
        "# créer la couche de sortie qui contient un nombre de neurones égale\n",
        "# au nombre de classes du dataset\n",
        "output_layer = keras.layers.Dense(units=nb_classes,activation='softmax')(flatenned_layer_2)\n",
        "\n",
        "# créer le modèle en spécifiant input et output\n",
        "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# choisir le taux d'apprentissage\n",
        "learning_rate = 0.1\n",
        "\n",
        "# choisir l'algorithme d'optimsation en lui spécifiant le taux d'aprentissage\n",
        "optimizer_algo = keras.optimizers.SGD(lr=learning_rate)\n",
        "\n",
        "# choisir la fonction de coût: categorical cross entropy\n",
        "cost_function = keras.losses.categorical_crossentropy\n",
        "\n",
        "# compiler le modèle en lui spécifiant qu'on veut surveiller l'accuracy\n",
        "model.compile(loss=cost_function,optimizer=optimizer_algo, metrics=['accuracy'])\n",
        "\n",
        "# choisir le batch size\n",
        "mini_batch_size = 256\n",
        "\n",
        "# choisir le nombre d'époque\n",
        "nb_epochs = 100\n",
        "\n",
        "# spécifier le model checkpoint (pour sauveguarder le meilleur modèle à chaque époque )\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint('best-model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# spécifier le pourcentage pour la validation\n",
        "percentage_of_train_as_validation = 0.3\n",
        "\n",
        "# commencer l'entrainement\n",
        "history = model.fit(x_train,y_train_binaire,batch_size=mini_batch_size,epochs=nb_epochs,\n",
        "                    validation_split=percentage_of_train_as_validation,verbose=False,\n",
        "                   callbacks=[model_checkpoint])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO-5P7b8UlPq"
      },
      "source": [
        "### Tracer la variation de l'accuracy (non pas le coût) en fonction du nombre d'epoques (donc utiliser 'acc' au lieu de 'loss')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0jUjt5z6IVg"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SySyeSeA6Jyp"
      },
      "source": [
        " ### Corrigé :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g7VRO6EUsjM"
      },
      "source": [
        "history_dict = history.history\n",
        "loss_train_epochs = history_dict['accuracy']\n",
        "loss_val_epochs = history_dict['val_accuracy']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_train_epochs,color='blue',label='train_acc')\n",
        "plt.plot(loss_val_epochs,color='red',label='val_acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh5Ym2gkT1mD"
      },
      "source": [
        "### Afficher le summary de votre modèle et analyser la sortie (cette étape peut-être faite avant l'entrainement)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS9KwqGI6MGk"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SynbRvp06Ngw"
      },
      "source": [
        " ### Corrigé :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWqy1I7wT5_H"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9qP2oPOTnv3"
      },
      "source": [
        "### Choisir le modèle sauveguardé"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26-7-70m6P1F"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhZtScYm6Q_N"
      },
      "source": [
        " ### Corrigé :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGnFbJ_fTsVn"
      },
      "source": [
        "model = keras.models.load_model('best-model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3c1pM9qS_Bo"
      },
      "source": [
        "### Évaluer le model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGFlzxPo6Tew"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz509UA36UrL"
      },
      "source": [
        " ### Corrigé :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl15dfc5Tj--"
      },
      "source": [
        "# evaluation sur train\n",
        "loss,acc = model.evaluate(x_train,y_train_binaire,verbose=False)\n",
        "print(\"L'accuracy sur l'ensemble du train est:\",acc)\n",
        "\n",
        "# evaluation sur le test\n",
        "loss,acc = model.evaluate(x_test,y_test_binaire,verbose=False)\n",
        "print(\"L'accuracy sur l'ensemble du test est:\",acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHKqfFio6EhE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}